# ğŸ›¡ï¸ Content Moderation System

## ğŸ“– Overview
This project is a **Content Moderation System** designed to analyze user-generated text (e.g., chat messages, comments, social media posts) and classify them as **SAFE**, **SUSPICIOUS**, or **HARMFUL**.  
The system combines **rule-based techniques** (detecting offensive words, repeated characters, URLs, excessive capitalization) with **machine learning models** to improve detection accuracy.

---

## âš™ï¸ Features
- **Rule-based Filtering**  
  - Detects offensive words, hate speech, threats, insults, spam-like content, and URLs.  
- **Machine Learning Models**  
  - TF-IDF vectorization + classifiers: Logistic Regression, SVM, Random Forest, XGBoost.  
- **Hybrid Scoring System**  
  - Weighted combination of rule-based score and ML probability for final decision.  
- **Streamlit Web App**  
  - User-friendly interface for inputting text.  
  - Shows scores, final decision, and reasons for moderation.

## ğŸ–¥ï¸ User Interface (UI)

The system has a simple and interactive **Streamlit interface** where users can input comments and get instant moderation results.  

### Example Screenshot
![alt text](assets/UI_Scr1.png)
![alt text](assets/UI_Scr2.png)

- **Text Area:** Users type any comment or text.  
- **Analyze Button:** Runs the hybrid moderation system.  
- **Results Panel:** Shows scores, final decision, and reasons for flagging.  

---

## ğŸ“‚ Project Structure

content_moderation/
â”‚â”€â”€ data/
â”‚ â”œâ”€â”€ train.csv
â”‚ â”œâ”€â”€ test.csv
â”‚â”€â”€ models/
â”‚ â”œâ”€â”€ log_reg_model.pkl
â”‚ â”œâ”€â”€ svm_model.pkl
â”‚ â”œâ”€â”€ random_forest_model.pkl
â”‚ â”œâ”€â”€ xgboost_model.pkl
â”‚ â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚â”€â”€ app.py
â”‚â”€â”€ train.py
â”‚â”€â”€ rules.py
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt 

---

## ğŸš€ Setup & Installation

1ï¸âƒ£ **Clone the repository**  
```bash
git clone https://github.com/your-username/content-moderation.git
cd content-moderation

2ï¸âƒ£ Create a virtual environment & activate it 
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt
 
 ğŸ‹ï¸ Training Models

Run the training script to train ML models and save them: 

python train.py

This generates .pkl files in models/:

log_reg_model.pkl

svm_model.pkl

random_forest_model.pkl

xgboost_model.pkl

tfidf_vectorizer.pkl 

ğŸ¯ Running the Streamlit App

streamlit run app.py

Example Interaction

I hate you, idiot!

Analysis Result:

Rule-based score: 1
ML score: 0.038
Final score: 0.326
Decision: SUSPICIOUS
Reasons:
- Offensive word detected
- ML probability = 0.038

ğŸ“Œ Scoring System

Rule-based score: Count of rule violations (0â€“4).

ML score: Probability predicted by the model (0â€“1).

Final score: Weighted sum: (rule_score * 0.3) + (ML_prob * 0.7)

Decision:

SAFE â†’ final score below threshold

SUSPICIOUS â†’ final score above threshold

HARMFUL â†’ final score high

ğŸ‘©â€ğŸ’» Author

Zeinab Ahmed
AI & Data Science Enthusiast